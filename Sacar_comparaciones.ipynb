{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["kP0Oq4v0c-2K","HTPo6rgsdIvI","RI2FMgIYc0pG","Mu8W6UOOc4Or"],"authorship_tag":"ABX9TyMcWwQA5HBTvcEak6asB1t8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importación de librerias"],"metadata":{"id":"kP0Oq4v0c-2K"}},{"cell_type":"code","source":["!pip install git+https://github.com/tensorflow/examples.git\n","!pip install -U kaleido"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRqLeLFHscvo","executionInfo":{"status":"ok","timestamp":1671710071929,"user_tz":-60,"elapsed":22000,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"}},"outputId":"7c449c2b-acaf-41ed-e8a7-47f8189b116a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/tensorflow/examples.git\n","  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-fznqj6wg\n","  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-fznqj6wg\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-examples===6ae97eaf3dbd607ed3eccf18f7dc05d7a3b677e3-) (1.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow-examples===6ae97eaf3dbd607ed3eccf18f7dc05d7a3b677e3-) (1.15.0)\n","Building wheels for collected packages: tensorflow-examples\n","  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-examples: filename=tensorflow_examples-6ae97eaf3dbd607ed3eccf18f7dc05d7a3b677e3_-py3-none-any.whl size=299717 sha256=4d6584f7610dcdb3c92dce26263298c45351944236979c47a0050c56a12d1ac0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dn41psay/wheels/4e/f5/c2/bfe75b834c9028b2529023bf74541c46ead531b513a8010d21\n","\u001b[33m  WARNING: Built wheel for tensorflow-examples is invalid: Metadata 1.2 mandates PEP 440 version, but '6ae97eaf3dbd607ed3eccf18f7dc05d7a3b677e3-' is not\u001b[0m\n","Failed to build tensorflow-examples\n","Installing collected packages: tensorflow-examples\n","    Running setup.py install for tensorflow-examples ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: tensorflow-examples was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n","Successfully installed tensorflow-examples-6ae97eaf3dbd607ed3eccf18f7dc05d7a3b677e3-\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[K     |████████████████████████████████| 79.9 MB 112 kB/s \n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaTw8R2xb4SF","executionInfo":{"status":"ok","timestamp":1671710093371,"user_tz":-60,"elapsed":21447,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"}},"outputId":"9212bd92-9ead-4493-b0f7-795b18f60251"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import random\n","import os\n","import plotly.graph_objects as px\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Creación de variables y fuciones"],"metadata":{"id":"HTPo6rgsdIvI"}},{"cell_type":"markdown","source":["## Ajustes visualización"],"metadata":{"id":"RI2FMgIYc0pG"}},{"cell_type":"code","source":["def one_hot_mask(y):\n","    ''' Do the one hot encoding for the masks.\n","  \n","    Arguments:\n","        - y (tf tensor): Mask of shape (height, width, 3)\n","\n","    Returns:\n","        - mask (tf tensor): Mask after do the one hot. Shape (height, width, num_classes) '''\n","\n","    one_hot_map = []\n","    for color in colors:\n","        class_map = tf.reduce_all(tf.equal(y, color), axis = -1)\n","        one_hot_map.append(class_map)\n","    mask = tf.cast(tf.stack(one_hot_map, axis = -1), tf.int32)\n","    return mask\n","\n","\n","def load_image(folder, file, height = 96, width = 256, crop = False):\n","    ''' Load and preprocess a train image by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Normalize the image to [0, 1]\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image '''\n","\n","    # Load the image (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.float32)\n","\n","    # Crop the image\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the image\n","    image = tf.image.resize(image, (height, width))\n","\n","    # Normalize the image\n","    image = tf.cast(image, tf.float32)/255.0\n","    return image\n","\n","\n","def load_mask(folder, file, height = 96, width = 256, one_hot = True, crop = False):\n","    ''' Load and preprocess a train mask by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Reshaping the mask from (height, width, 3) to (height, width, 30): One hot encoding\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - one_hot (bool): Do one hot encoding or not -- True\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed mask '''\n","\n","    # Load the mask (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.int32)\n","\n","    # Crop the mask\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the mask\n","    image = tf.image.resize(image, (height, width), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","    # One hot encoding\n","    if one_hot:\n","        image = one_hot_mask(image)\n","    return image\n","\n","\n","def one_hot_to_color_mask(mask, colors, img_height = 96, img_width = 256):\n","    ''' Convert from the mask from the classes with highest probablities to the correct color. From (96, 256, 1) to (96, 256, 3).\n","  \n","    Arguments:\n","        - mask (tf tensor): Mask with the classes with highest probabilities\n","        - colors (list): List with the class colors\n","        - img_height (int): Height of the images -- 96\n","        - img_width (int): Width of the images -- 256\n","\n","    Returns:\n","        - color_mask (tf tensor): Color mask '''\n","\n","    color_mask = np.zeros((img_height, img_width, channels)).astype('float')\n","    for c in range(len(colors)):\n","        color_true = mask == c\n","        for i in range(3):\n","            color_mask[:,:,i] += color_true*colors[c][i]\n","\n","    color_mask = tf.cast(color_mask, dtype = tf.int32)\n","\n","    return color_mask\n","\n","def load_train(image_name, mask_name):\n","    ''' Load and preprocess a train image and its mask\n","  \n","    Arguments:\n","        - image_name (string): Name of the image to load\n","        - mask_name (string): Name of the mask to load\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image\n","        - mask (tf tensor): Preprocessed mask '''\n","\n","    image = load_image(train_images_folder_path, image_name, img_height, img_width)\n","    mask = load_mask(train_mask_folder_path, mask_name, img_height, img_width)\n","    return image, mask"],"metadata":{"id":"qrukqIGVczbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images_folder_path = \"/content/drive/My Drive\" \n","train_mask_folder_path = \"/content/drive/MyDrive/GTA Segmentacion\" \n","\n","img_height, img_width, channels = 96, 256, 3\n","\n","batch_size = 2\n","\n","colors = np.array([(0, 0, 0), (111, 74, 0), (81, 0, 81), (128, 64, 128), (244, 35, 232), (250, 170, 160), (230, 150, 140), (70, 70, 70), (102, 102, 156), (190, 153, 153), (180, 165, 180), \n","                   (150, 100, 100), (150, 120, 90), (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60), (255, 0, 0), ( 0, 0, 142), \n","                   ( 0, 0, 70), (0, 60, 100), (0, 0, 90), (0, 0, 110), (0, 80, 100), (0, 0, 230), (119, 11, 32), (0, 0, 142)], dtype = np.int32)\n","\n","model = tf.keras.models.load_model('/content/drive/My Drive/Modelo_segmentacion_UNET/best_model_weights_and_architecture')"],"metadata":{"id":"FCpjIh8NcENe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inicialización"],"metadata":{"id":"Mu8W6UOOc4Or"}},{"cell_type":"code","source":["path_result = \"/content/drive/MyDrive/Resultados/\"\n","path_GTA = \"/content/drive/MyDrive/GTA/\"\n","\n","rango = [\"Original\", \"Best NST\", \"CycleGAN-6\", \"CycleGAN-10\", \"CycleGAN-12\"]\n","imgs = [\"01526.png\", \"00031.png\", \"00513.png\", \"01166.png\", \"01151.png\", \"01782.png\", \"01550.png\", \"01450.png\", \"00557.png\", \"02078.png\",  # 10 primeros\n","        \"01575.png\", \"00370.png\", \"01401.png\", \"01999.png\", \"00203.png\", \"00560.png\", \"00142.png\", \"02074.png\", \"02406.png\", \"00467.png\",\n","        \"01889.png\", \"00466.png\", \"02307.png\", \"00529.png\", \"02071.png\", \"00045.png\", \"00301.png\", \"00491.png\", \"00078.png\", \"01289.png\",\n","        \"01862.png\", \"02264.png\", \"01297.png\", \"01385.png\", \"01348.png\", \"02019.png\", \"02099.png\", \"00242.png\", \"01101.png\", \"02313.png\",\n","        \"01655.png\", \"00923.png\", \"01495.png\", \"01947.png\", \"02404.png\", \"01293.png\", \"00733.png\", \"01579.png\", \"01701.png\", \"00248.png\", \n","        \"01597.png\", \"01665.png\", \"01909.png\", \"00857.png\", \"00646.png\", \"02134.png\", \"00993.png\", \"01394.png\", \"01600.png\", \"01012.png\"]\n","\n","itera = 60  # Número de imagenes de prueba\n","\n","list_GTA = os.listdir(path_GTA)\n","images_GTA = random.choices(list_GTA, k=itera)\n","\n","for i in range(itera):\n","  images_GTA[i] = path_GTA + imgs[i]"],"metadata":{"id":"3gWsexCPcELc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Automático para muchos"],"metadata":{"id":"zzrRjWJoqXX2"}},{"cell_type":"code","source":["all_iou = []\n","all_half_iou = []\n","\n","for num in range(0, itera):\n","\n","# NST  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  images_name = [\"GTA/\" + imgs[num], \n","                 \"Resultados/AA_NST_50_\" + str(num+1) + \".png\", \"Resultados/AA_NST_75_\" + str(num+1) + \".png\", \"Resultados/AA_NST_100_\" + str(num+1) + \".png\",\n","                 \"Resultados/AA_NST_200_\" + str(num+1) + \".png\", \"Resultados/AA_NST_500_\" + str(num+1) + \".png\", \"Resultados/AA_NST_1000_\" + str(num+1) + \".png\"]\n","\n","  mask_names = ((images_GTA[num].split(\"/\")[-1] + \" \") * 7).split()\n","\n","  dataset = tf.data.Dataset.from_tensor_slices((images_name, mask_names))\n","  dataset = dataset.map(load_train, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","  dataset = dataset.batch(batch_size)\n","\n","  predictions = model.predict(dataset, batch_size = 10)\n","  predictions = np.argmax(predictions, axis = 3)\n","\n","  idx = range(len(images_name))\n","  visualize_images = [load_image(train_images_folder_path, images_name[i], img_height, img_width) for i in idx]\n","  visualize_masks = [load_mask(train_mask_folder_path, mask_names[i], img_height, img_width, one_hot = False) for i in idx]\n","  preds = predictions[idx]\n","\n","  iou_score = []\n","  iou_score_half = []\n","\n","  for k in range(len(images_name)):\n","    output = one_hot_to_color_mask(preds[k], colors)\n","\n","  # IoU calculation\n","    intersection = 0\n","    union = img_height * img_width\n","\n","    for i in range(img_height):\n","      for j in range(img_width):\n","        a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","        if sum(a.numpy())==3:\n","          intersection += 1\n","\n","    iou_score.append(intersection/union)\n","\n","  # Calcula de la mitad hacia abajo\n","    intersection = 0\n","    union = int(img_height/2) * img_width\n","\n","    for i in range(int(img_height/2), img_height):\n","        for j in range(img_width):\n","          a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","          if sum(a.numpy())==3:\n","            intersection += 1\n","\n","    iou_score_half.append(intersection/union)\n","\n","  max_val_pos = iou_score_half.index(max(iou_score_half[1:]))\n","\n","\n","# GAN  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  images_name = [\"Resultados/Output_GAN_6_\" + str(num+1) + \".png\", \"Resultados/Output_GAN_10_\" + str(num+1) + \".png\", \"Resultados/Output_GAN_12_\" + str(num+1) + \".png\"]\n","\n","  mask_names = ((images_GTA[num].split(\"/\")[-1] + \" \") * 3).split()\n","\n","  dataset = tf.data.Dataset.from_tensor_slices((images_name, mask_names))\n","  dataset = dataset.map(load_train, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","  dataset = dataset.batch(batch_size)\n","\n","  predictions = model.predict(dataset, batch_size = 10)\n","  predictions = np.argmax(predictions, axis = 3)\n","\n","  idx = range(len(images_name))\n","  visualize_images = [load_image(train_images_folder_path, images_name[i], img_height, img_width) for i in idx]\n","  visualize_masks = [load_mask(train_mask_folder_path, mask_names[i], img_height, img_width, one_hot = False) for i in idx]\n","  preds = predictions[idx]\n","\n","  iou_score_defin = [iou_score[0]]\n","  iou_score_half_defin = [iou_score_half[0]]\n","  iou_score_defin.append(iou_score[max_val_pos])\n","  iou_score_half_defin.append(iou_score_half[max_val_pos])\n","\n","  for k in range(len(images_name)):\n","    output = one_hot_to_color_mask(preds[k], colors)\n","    \n","  # IoU calculation\n","    intersection = 0\n","    union = img_height * img_width\n","\n","    for i in range(img_height):\n","      for j in range(img_width):\n","        a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","        if sum(a.numpy())==3:\n","          intersection += 1\n","\n","    iou_score_defin.append(intersection/union)\n","    \n","  # Calcula de la mitad hacia abajo\n","    intersection = 0\n","    union = int(img_height/2) * img_width\n","\n","    for i in range(int(img_height/2), img_height):\n","      for j in range(img_width):\n","        a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","        if sum(a.numpy())==3:\n","          intersection += 1\n","\n","    iou_score_half_defin.append(intersection/union)\n","\n","# Visualización final 1 (gráfico) &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  fig = px.Figure(data=[px.Bar(x = rango, y = iou_score_defin, name = \"Completa\"),\n","                        px.Bar(x = rango, y = iou_score_half_defin, name = \"Mitad\")])\n","\n","  fig.update_layout(title=\"IoU respecto al método utilizado\",\n","                    xaxis_title=\"Método\",\n","                    yaxis_title=\"IoU\",\n","                    autosize=False)\n","  fig.update_yaxes(range=[0, 1])\n","  fig.show()\n","  fig.write_image(path_result + \"Comparacion_IoU_todos_\" + str(num+1) + \".png\")\n","\n","  print(\"Completado el\", str(num+1))\n","\n","  all_iou.append(iou_score_defin)\n","  all_half_iou.append(iou_score_half_defin)\n","\n","# Visualización final 2 (gráfico general) &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","iou_bar = list(np.mean(all_iou, axis=0))\n","iou_half_bar = list(np.mean(all_half_iou, axis=0))\n","\n","fig = px.Figure(data=[px.Bar(x = rango, y = iou_bar, name = 'Completa', error_y=dict(type='percent', value=100/3)),\n","                      px.Bar(x = rango, y = iou_half_bar, name = 'Mitad', error_y=dict(type='percent', value=100/3))])\n","\n","fig.update_layout(title=\"Media de todos los IoUs respecto al método utilizado\",\n","                  xaxis_title=\"Método\",\n","                  yaxis_title=\"IoU medio\",\n","                  autosize=False)\n","fig.update_yaxes(range=[0, 1])\n","fig.show()\n","fig.write_image(path_result + \"Comparacion_IoU_general.png\")"],"metadata":{"id":"bXcwfzA4chcB"},"execution_count":null,"outputs":[]}]}