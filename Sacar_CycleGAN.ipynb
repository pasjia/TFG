{"cells":[{"cell_type":"markdown","metadata":{"id":"L6ejeVWQlC2r"},"source":["# Importaci칩n de librerias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15515,"status":"ok","timestamp":1669822479146,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"},"user_tz":-60},"id":"gjmpMw3ibS2e","outputId":"70ecdf33-de12-4864-ffc9-99c3ad0c3ca5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/tensorflow/examples.git\n","  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-h89jp0v_\n","  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-h89jp0v_\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-examples===2741b9ea31622676451e2ce1414d233de45f915f-) (1.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-examples===2741b9ea31622676451e2ce1414d233de45f915f-) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"]}],"source":["!pip install git+https://github.com/tensorflow/examples.git\n","!pip install -U kaleido"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2503,"status":"ok","timestamp":1669822481643,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"},"user_tz":-60},"id":"udexQExIbZYU","outputId":"98fe6567-7a29-49b4-fe25-23fbc486bc67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import random\n","import os\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as px\n","\n","import PIL.Image\n","\n","import cv2\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Nx3vpg7TfFTT"},"source":["# Creaci칩n de variables y fuciones"]},{"cell_type":"markdown","metadata":{"id":"eV5ITTLefOeX"},"source":["## Ajustes GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h998DHyFbjAf"},"outputs":[],"source":["def generator_gta():\n","    for path in images_GTA:\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (286,286))\n","        yield img\n","\n","\n","def generator_cityscapes():\n","    for path in images_Reales:\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (286,286))\n","        yield img\n","\n","\n","def preprocess_imgs(img):\n","    ## Convertimos las im치genes de int a float\n","    img = tf.cast(img, tf.float32)\n","\n","    ## Normalizamos al rango [-1,1]\n","    img = (img/127.5) - 1\n","\n","    ## Extraemos recortes aleatorios de 256x256\n","    img = tf.image.random_crop(img, size=[256, 256, 3])\n","\n","    return img\n","\n","\n","def renormalize(img, contrast=1):\n","    return img*0.5*contrast + 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuHwlf0Mbi1M"},"outputs":[],"source":["OUTPUT_CHANNELS = 3\n","\n","generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","\n","discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","\n","\n","generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","checkpoint_path = \"./Checkpoints/\"\n","\n","ckpt = tf.train.Checkpoint(generator_g=generator_g,\n","                           generator_f=generator_f,\n","                           discriminator_x=discriminator_x,\n","                           discriminator_y=discriminator_y,\n","                           generator_g_optimizer=generator_g_optimizer,\n","                           generator_f_optimizer=generator_f_optimizer,\n","                           discriminator_x_optimizer=discriminator_x_optimizer,\n","                           discriminator_y_optimizer=discriminator_y_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"]},{"cell_type":"markdown","metadata":{"id":"EwIv0X3rfRFn"},"source":["## Ajustes visualizaci칩n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HBMlEJbcBSD"},"outputs":[],"source":["def one_hot_mask(y):\n","    ''' Do the one hot encoding for the masks.\n","  \n","    Arguments:\n","        - y (tf tensor): Mask of shape (height, width, 3)\n","\n","    Returns:\n","        - mask (tf tensor): Mask after do the one hot. Shape (height, width, num_classes) '''\n","\n","    one_hot_map = []\n","    for color in colors:\n","        class_map = tf.reduce_all(tf.equal(y, color), axis = -1)\n","        one_hot_map.append(class_map)\n","    mask = tf.cast(tf.stack(one_hot_map, axis = -1), tf.int32)\n","    return mask\n","\n","\n","def load_image(folder, file, height = 96, width = 256, crop = False):\n","    ''' Load and preprocess a train image by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Normalize the image to [0, 1]\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image '''\n","\n","    # Load the image (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.float32)\n","\n","    # Crop the image\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the image\n","    image = tf.image.resize(image, (height, width))\n","\n","    # Normalize the image\n","    image = tf.cast(image, tf.float32)/255.0\n","    return image\n","\n","\n","def load_mask(folder, file, height = 96, width = 256, one_hot = True, crop = False):\n","    ''' Load and preprocess a train mask by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Reshaping the mask from (height, width, 3) to (height, width, 30): One hot encoding\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - one_hot (bool): Do one hot encoding or not -- True\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed mask '''\n","\n","    # Load the mask (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.int32)\n","\n","    # Crop the mask\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the mask\n","    image = tf.image.resize(image, (height, width), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","    # One hot encoding\n","    if one_hot:\n","        image = one_hot_mask(image)\n","    return image\n","\n","\n","def one_hot_to_color_mask(mask, colors, img_height = 96, img_width = 256):\n","    ''' Convert from the mask from the classes with highest probablities to the correct color. From (96, 256, 1) to (96, 256, 3).\n","  \n","    Arguments:\n","        - mask (tf tensor): Mask with the classes with highest probabilities\n","        - colors (list): List with the class colors\n","        - img_height (int): Height of the images -- 96\n","        - img_width (int): Width of the images -- 256\n","\n","    Returns:\n","        - color_mask (tf tensor): Color mask '''\n","\n","    color_mask = np.zeros((img_height, img_width, channels)).astype('float')\n","    for c in range(len(colors)):\n","        color_true = mask == c\n","        for i in range(3):\n","            color_mask[:,:,i] += color_true*colors[c][i]\n","\n","    color_mask = tf.cast(color_mask, dtype = tf.int32)\n","\n","    return color_mask\n","\n","def load_train(image_name, mask_name):\n","    ''' Load and preprocess a train image and its mask\n","  \n","    Arguments:\n","        - image_name (string): Name of the image to load\n","        - mask_name (string): Name of the mask to load\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image\n","        - mask (tf tensor): Preprocessed mask '''\n","\n","    image = load_image(train_images_folder_path, image_name, img_height, img_width)\n","    mask = load_mask(train_mask_folder_path, mask_name, img_height, img_width)\n","    return image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZljlfDWJgebd"},"outputs":[],"source":["train_images_folder_path = \"/content/drive/My Drive\" \n","train_mask_folder_path = \"/content/drive/MyDrive/GTA Segmentacion\" \n","\n","img_height, img_width, channels = 96, 256, 3\n","\n","batch_size = 2\n","\n","colors = np.array([(0, 0, 0), (111, 74, 0), (81, 0, 81), (128, 64, 128), (244, 35, 232), (250, 170, 160), (230, 150, 140), (70, 70, 70), (102, 102, 156), (190, 153, 153), (180, 165, 180), \n","                   (150, 100, 100), (150, 120, 90), (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60), (255, 0, 0), ( 0, 0, 142), \n","                   ( 0, 0, 70), (0, 60, 100), (0, 0, 90), (0, 0, 110), (0, 80, 100), (0, 0, 230), (119, 11, 32), (0, 0, 142)], dtype = np.int32)\n","\n","model = tf.keras.models.load_model('/content/drive/My Drive/Modelo_segmentacion_UNET/best_model_weights_and_architecture')\n","\n","rango = [\"Original\", \"CycleGAN-6\", \"CycleGAN-10\", \"CycleGAN-12\"]"]},{"cell_type":"markdown","metadata":{"id":"Q8fKCOyBfbEL"},"source":["# Inicializaci칩n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GREBr28bZVq"},"outputs":[],"source":["path_result = \"/content/drive/MyDrive/Resultados/\"\n","\n","path_GTA = \"/content/drive/MyDrive/GTA/\"\n","path_Reales = \"/content/drive/MyDrive/Reales/\"\n","\n","iter = 10  # N칰mero de imagenes de prueba\n","\n","list_GTA = os.listdir(path_GTA)\n","images_GTA = random.choices(list_GTA, k=iter)\n","\n","list_Reales = os.listdir(path_Reales)\n","images_Reales = random.choices(list_Reales, k=iter)\n","\n","for i in range(iter):\n","  images_GTA[i] = path_GTA + images_GTA[i]\n","  images_Reales[i] = path_Reales + images_Reales[i]"]},{"cell_type":"markdown","metadata":{"id":"NImACSydk5uQ"},"source":["## Cambiar alguna imagen si hace falta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxCfm4QOAlrT"},"outputs":[],"source":["a = [\"01526.png\", \"00031.png\", \"00513.png\", \"01166.png\", \"01151.png\", \"01782.png\", \"01550.png\", \"01450.png\", \"00557.png\", \"02078.png\"]\n","\n","b = [\"bremen_000152_000019_leftImg8bit.png\", \"stuttgart_000115_000019_leftImg8bit.png\", \"dusseldorf_000141_000019_leftImg8bit.png\",\n"," \"monchengladbach_000000_007098_leftImg8bit.png\", \"cologne_000006_000019_leftImg8bit.png\", \"bremen_000256_000019_leftImg8bit.png\",\n"," \"bremen_000190_000019_leftImg8bit.png\", \"cologne_000072_000019_leftImg8bit.png\", \"cologne_000064_000019_leftImg8bit.png\", \"strasbourg_000000_029020_leftImg8bit.png\"]\n","\n","\n","for i in range(iter):\n","  images_GTA[i] = path_GTA + a[i]\n","  images_Reales[i] = path_Reales + b[i]"]},{"cell_type":"markdown","source":["## Im치genes que se han escogido"],"metadata":{"id":"kq9L0vIuovJ0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669819497741,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"},"user_tz":-60},"id":"XpH147INf0Vx","outputId":"081e8cdf-da72-4fe6-a933-32b4de23d1b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["01526.png\n","00031.png\n","00513.png\n","01166.png\n","01151.png\n","01782.png\n","01550.png\n","01450.png\n","00557.png\n","02078.png\n","------------------------------------------------\n","bremen_000152_000019_leftImg8bit.png\n","stuttgart_000115_000019_leftImg8bit.png\n","dusseldorf_000141_000019_leftImg8bit.png\n","monchengladbach_000000_007098_leftImg8bit.png\n","cologne_000006_000019_leftImg8bit.png\n","bremen_000256_000019_leftImg8bit.png\n","bremen_000190_000019_leftImg8bit.png\n","cologne_000072_000019_leftImg8bit.png\n","cologne_000064_000019_leftImg8bit.png\n","strasbourg_000000_029020_leftImg8bit.png\n"]}],"source":["for name in images_GTA:\n","  print(name.split(\"/\")[-1])\n","print(\"------------------------------------------------\")\n","for name in images_Reales:\n","  print(name.split(\"/\")[-1])"]},{"cell_type":"markdown","source":["## Creamos la estructura de los datos"],"metadata":{"id":"rHClNtuAo2rH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8Kl4YDMbi5u"},"outputs":[],"source":["dataset_gta = tf.data.Dataset.from_generator(\n","    generator_gta,\n","    output_signature=(\n","        tf.TensorSpec((286, 286, 3), tf.int32)\n","    )\n",")\n","\n","dataset_cityscapes = tf.data.Dataset.from_generator(\n","    generator_cityscapes,\n","    output_signature=(\n","        tf.TensorSpec((286, 286, 3), tf.int32)\n","    )\n",")\n","\n","dataset_gta_rdy = dataset_gta.map(preprocess_imgs)\n","dataset_cityscapes_rdy = dataset_cityscapes.map(preprocess_imgs)\n","\n","dataset_full = tf.data.Dataset.zip((dataset_gta_rdy, dataset_cityscapes_rdy))"]},{"cell_type":"markdown","metadata":{"id":"OBZxzvSVk1c2"},"source":["# Autom치tico para muchos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3D4-nh7bZTR"},"outputs":[],"source":["for num in range(iter):\n","\n","# GAN  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  i = 0\n","  for a, b in dataset_full.batch(1):\n","    if i==num:\n","      img_gta = a\n","      img_cs = b\n","    i += 1\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-6')\n","  Output_GAN_6 = generator_g.predict(img_gta)\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-10')\n","  Output_GAN_10 = generator_g.predict(img_gta)\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-12')\n","  Output_GAN_12 = generator_g.predict(img_gta)\n","\n","# Guardamos los resultados\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_6.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_6_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_10.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_10_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_12.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_12_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","\n","# Segmentaci칩n  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  images_name = [\"GTA/\" + images_GTA[num].split(\"/\")[-1], \"Resultados/Output_GAN_6_\" + str(num+1) + \".png\",\n","                 \"Resultados/Output_GAN_10_\" + str(num+1) + \".png\", \"Resultados/Output_GAN_12_\" + str(num+1) + \".png\"]\n","\n","  mask_names = ((images_name[0].split(\"/\")[-1] + \" \") * 4).split()\n","\n","  dataset = tf.data.Dataset.from_tensor_slices((images_name, mask_names))\n","  dataset = dataset.map(load_train, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","  dataset = dataset.batch(batch_size)\n","\n","  predictions = model.predict(dataset, batch_size = 10)\n","  predictions = np.argmax(predictions, axis = 3)\n","\n","  idx = range(len(images_name))\n","  visualize_images = [load_image(train_images_folder_path, images_name[i], img_height, img_width) for i in idx]\n","  visualize_masks = [load_mask(train_mask_folder_path, mask_names[i], img_height, img_width, one_hot = False) for i in idx]\n","  preds = predictions[idx]\n","\n","  iou_score = []\n","  iou_score_half = []\n","\n","  plt.figure(figsize = (16, 4))\n","  plt.subplots_adjust(hspace = 0.1)\n","\n","  for k in range(4):\n","    plt.subplot(3, 4, k + 1)\n","    plt.imshow(visualize_images[k])\n","    if k==0:\n","      plt.ylabel(\"Input\")\n","    plt.title(rango[k])\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","    plt.subplot(3, 4, k + 5)\n","    plt.imshow(visualize_masks[k])\n","    if k==0:\n","      plt.ylabel(\"Ground Truth\")\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","    output = one_hot_to_color_mask(preds[k], colors)\n","# IoU calculation\n","    intersection = 0\n","    union = img_height * img_width\n","\n","    for i in range(img_height):\n","      for j in range(img_width):\n","        a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","        if sum(a.numpy())==3:\n","          intersection += 1\n","\n","    iou_score.append(intersection/union)\n","    \n","# Calcula de la mitad hacia abajo\n","    intersection = 0\n","    union = int(img_height/2) * img_width\n","\n","    for i in range(int(img_height/2), img_height):\n","        for j in range(img_width):\n","          a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","          if sum(a.numpy())==3:\n","            intersection += 1\n","\n","    iou_score_half.append(intersection/union)\n","    \n","    plt.subplot(3, 4, k + 9)\n","    plt.imshow(output)\n","    if k==0:\n","      plt.ylabel(\"Output\")\n","    plt.xlabel(\"IoU: %s\" % iou_score[k])\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","  plt.savefig(path_result + \"Output_GTA_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  print(\"Completado el\", str(num+1))"]}],"metadata":{"colab":{"collapsed_sections":["L6ejeVWQlC2r","EwIv0X3rfRFn"],"provenance":[],"authorship_tag":"ABX9TyPwE5FJt6eDF5ss4T5cWKoj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}