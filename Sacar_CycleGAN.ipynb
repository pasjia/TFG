{"cells":[{"cell_type":"markdown","metadata":{"id":"L6ejeVWQlC2r"},"source":["# Importación de librerias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47181,"status":"ok","timestamp":1676109464813,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"},"user_tz":-60},"id":"gjmpMw3ibS2e","outputId":"90caf0c4-e883-4818-d6c5-a6563a9487f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/tensorflow/examples.git\n","  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-h8n3_3mc\n","  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/examples.git /tmp/pip-req-build-h8n3_3mc\n","  Resolved https://github.com/tensorflow/examples.git to commit a71f7e38b0ce56e9f39d8049e836ea8f7af74f83\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-examples===a71f7e38b0ce56e9f39d8049e836ea8f7af74f83-) (1.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow-examples===a71f7e38b0ce56e9f39d8049e836ea8f7af74f83-) (1.15.0)\n","Building wheels for collected packages: tensorflow-examples\n","  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-examples: filename=tensorflow_examples-a71f7e38b0ce56e9f39d8049e836ea8f7af74f83_-py3-none-any.whl size=299718 sha256=e6ff4c3383a22f0c37cb16a82f29b95550ad3ae724e20a4fd5dfb976a5f4ad42\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qr6tyboe/wheels/4e/f5/c2/bfe75b834c9028b2529023bf74541c46ead531b513a8010d21\n","\u001b[33m  WARNING: Built wheel for tensorflow-examples is invalid: Metadata 1.2 mandates PEP 440 version, but 'a71f7e38b0ce56e9f39d8049e836ea8f7af74f83-' is not\u001b[0m\u001b[33m\n","\u001b[0mFailed to build tensorflow-examples\n","Installing collected packages: tensorflow-examples\n","  Running setup.py install for tensorflow-examples ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: tensorflow-examples was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed tensorflow-examples-a71f7e38b0ce56e9f39d8049e836ea8f7af74f83-\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n"]}],"source":["!pip install git+https://github.com/tensorflow/examples.git\n","!pip install -U kaleido"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29135,"status":"ok","timestamp":1676109493932,"user":{"displayName":"alex Pastor","userId":"13585304210710441676"},"user_tz":-60},"id":"udexQExIbZYU","outputId":"8b6c46ab-b1d5-4374-f6c6-8ac6792e046c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import random\n","import os\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as px\n","\n","import PIL.Image\n","\n","import cv2\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Nx3vpg7TfFTT"},"source":["# Creación de variables y fuciones"]},{"cell_type":"markdown","metadata":{"id":"eV5ITTLefOeX"},"source":["## Ajustes GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h998DHyFbjAf"},"outputs":[],"source":["def generator_gta():\n","    for path in images_GTA:\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (286,286))\n","        yield img\n","\n","\n","def generator_cityscapes():\n","    for path in images_Reales:\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (286,286))\n","        yield img\n","\n","\n","def preprocess_imgs(img):\n","    ## Convertimos las imágenes de int a float\n","    img = tf.cast(img, tf.float32)\n","\n","    ## Normalizamos al rango [-1,1]\n","    img = (img/127.5) - 1\n","\n","    ## Extraemos recortes aleatorios de 256x256\n","    img = tf.image.random_crop(img, size=[256, 256, 3])\n","\n","    return img\n","\n","\n","def renormalize(img, contrast=1):\n","    return img*0.5*contrast + 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuHwlf0Mbi1M"},"outputs":[],"source":["OUTPUT_CHANNELS = 3\n","\n","generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","\n","discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","\n","\n","generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","checkpoint_path = \"./Checkpoints/\"\n","\n","ckpt = tf.train.Checkpoint(generator_g=generator_g,\n","                           generator_f=generator_f,\n","                           discriminator_x=discriminator_x,\n","                           discriminator_y=discriminator_y,\n","                           generator_g_optimizer=generator_g_optimizer,\n","                           generator_f_optimizer=generator_f_optimizer,\n","                           discriminator_x_optimizer=discriminator_x_optimizer,\n","                           discriminator_y_optimizer=discriminator_y_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"]},{"cell_type":"markdown","metadata":{"id":"EwIv0X3rfRFn"},"source":["## Ajustes visualización"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HBMlEJbcBSD"},"outputs":[],"source":["def one_hot_mask(y):\n","    ''' Do the one hot encoding for the masks.\n","  \n","    Arguments:\n","        - y (tf tensor): Mask of shape (height, width, 3)\n","\n","    Returns:\n","        - mask (tf tensor): Mask after do the one hot. Shape (height, width, num_classes) '''\n","\n","    one_hot_map = []\n","    for color in colors:\n","        class_map = tf.reduce_all(tf.equal(y, color), axis = -1)\n","        one_hot_map.append(class_map)\n","    mask = tf.cast(tf.stack(one_hot_map, axis = -1), tf.int32)\n","    return mask\n","\n","\n","def load_image(folder, file, height = 96, width = 256, crop = False):\n","    ''' Load and preprocess a train image by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Normalize the image to [0, 1]\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image '''\n","\n","    # Load the image (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.float32)\n","\n","    # Crop the image\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the image\n","    image = tf.image.resize(image, (height, width))\n","\n","    # Normalize the image\n","    image = tf.cast(image, tf.float32)/255.0\n","    return image\n","\n","\n","def load_mask(folder, file, height = 96, width = 256, one_hot = True, crop = False):\n","    ''' Load and preprocess a train mask by:\n","        - Crop the image to not have the Mercedes-Benz star\n","        - Resize the image to (height, width)\n","        - Reshaping the mask from (height, width, 3) to (height, width, 30): One hot encoding\n","  \n","    Arguments:\n","        - folder (string): Path to the folder\n","        - file (string): Name of the file to load\n","        - height (int): Height to resize -- 96\n","        - width (int): Width to resize -- 256\n","        - one_hot (bool): Do one hot encoding or not -- True\n","        - crop (bool): Crpo the image or not -- True\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed mask '''\n","\n","    # Load the mask (png)\n","    image = tf.io.read_file(folder + '/' + file)\n","    image = tf.cast(tf.image.decode_png(image, channels = 3), tf.int32)\n","\n","    # Crop the mask\n","    if crop:\n","        image = tf.image.crop_to_bounding_box(image, 0, 0, 768, 2048)\n","\n","    # Resize the mask\n","    image = tf.image.resize(image, (height, width), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","    # One hot encoding\n","    if one_hot:\n","        image = one_hot_mask(image)\n","    return image\n","\n","\n","def one_hot_to_color_mask(mask, colors, img_height = 96, img_width = 256):\n","    ''' Convert from the mask from the classes with highest probablities to the correct color. From (96, 256, 1) to (96, 256, 3).\n","  \n","    Arguments:\n","        - mask (tf tensor): Mask with the classes with highest probabilities\n","        - colors (list): List with the class colors\n","        - img_height (int): Height of the images -- 96\n","        - img_width (int): Width of the images -- 256\n","\n","    Returns:\n","        - color_mask (tf tensor): Color mask '''\n","\n","    color_mask = np.zeros((img_height, img_width, channels)).astype('float')\n","    for c in range(len(colors)):\n","        color_true = mask == c\n","        for i in range(3):\n","            color_mask[:,:,i] += color_true*colors[c][i]\n","\n","    color_mask = tf.cast(color_mask, dtype = tf.int32)\n","\n","    return color_mask\n","\n","def load_train(image_name, mask_name):\n","    ''' Load and preprocess a train image and its mask\n","  \n","    Arguments:\n","        - image_name (string): Name of the image to load\n","        - mask_name (string): Name of the mask to load\n","\n","    Returns:\n","        - image (tf tensor): Preprocessed image\n","        - mask (tf tensor): Preprocessed mask '''\n","\n","    image = load_image(train_images_folder_path, image_name, img_height, img_width)\n","    mask = load_mask(train_mask_folder_path, mask_name, img_height, img_width)\n","    return image, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZljlfDWJgebd"},"outputs":[],"source":["train_images_folder_path = \"/content/drive/My Drive\" \n","train_mask_folder_path = \"/content/drive/MyDrive/GTA Segmentacion\" \n","\n","img_height, img_width, channels = 96, 256, 3\n","\n","batch_size = 2\n","\n","colors = np.array([(0, 0, 0), (111, 74, 0), (81, 0, 81), (128, 64, 128), (244, 35, 232), (250, 170, 160), (230, 150, 140), (70, 70, 70), (102, 102, 156), (190, 153, 153), (180, 165, 180), \n","                   (150, 100, 100), (150, 120, 90), (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60), (255, 0, 0), ( 0, 0, 142), \n","                   ( 0, 0, 70), (0, 60, 100), (0, 0, 90), (0, 0, 110), (0, 80, 100), (0, 0, 230), (119, 11, 32), (0, 0, 142)], dtype = np.int32)\n","\n","model = tf.keras.models.load_model('/content/drive/My Drive/Modelo_segmentacion_UNET/best_model_weights_and_architecture')\n","\n","# rango = [\"Original\", \"CycleGAN-6\", \"CycleGAN-10\", \"CycleGAN-12\"]"]},{"cell_type":"markdown","metadata":{"id":"Q8fKCOyBfbEL"},"source":["# Inicialización"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GREBr28bZVq"},"outputs":[],"source":["path_result = \"/content/drive/MyDrive/Resultados/\"\n","\n","path_GTA = \"/content/drive/MyDrive/GTA/\"\n","path_Reales = \"/content/drive/MyDrive/Reales/\"\n","\n","itera = 60  # Número de imagenes de prueba\n","\n","list_GTA = os.listdir(path_GTA)\n","images_GTA = random.choices(list_GTA, k=itera)\n","\n","list_Reales = os.listdir(path_Reales)\n","images_Reales = random.choices(list_Reales, k=itera)\n","\n","for i in range(itera):\n","  images_GTA[i] = path_GTA + images_GTA[i]\n","  images_Reales[i] = path_Reales + images_Reales[i]"]},{"cell_type":"markdown","metadata":{"id":"NImACSydk5uQ"},"source":["## Cambiar alguna imagen si hace falta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxCfm4QOAlrT"},"outputs":[],"source":["a = [\"01526.png\", \"00031.png\", \"00513.png\", \"01166.png\", \"01151.png\", \"01782.png\", \"01550.png\", \"01450.png\", \"00557.png\", \"02078.png\",  # 10 primeros\n","     \"01575.png\", \"00370.png\", \"01401.png\", \"01999.png\", \"00203.png\", \"00560.png\", \"00142.png\", \"02074.png\", \"02406.png\", \"00467.png\",\n","     \"01889.png\", \"00466.png\", \"02307.png\", \"00529.png\", \"02071.png\", \"00045.png\", \"00301.png\", \"00491.png\", \"00078.png\", \"01289.png\",\n","     \"01862.png\", \"02264.png\", \"01297.png\", \"01385.png\", \"01348.png\", \"02019.png\", \"02099.png\", \"00242.png\", \"01101.png\", \"02313.png\",\n","     \"01655.png\", \"00923.png\", \"01495.png\", \"01947.png\", \"02404.png\", \"01293.png\", \"00733.png\", \"01579.png\", \"01701.png\", \"00248.png\", \n","     \"01597.png\", \"01665.png\", \"01909.png\", \"00857.png\", \"00646.png\", \"02134.png\", \"00993.png\", \"01394.png\", \"01600.png\", \"01012.png\"]\n","\n","b = [\"bremen_000152_000019_leftImg8bit.png\", \"stuttgart_000115_000019_leftImg8bit.png\", \"dusseldorf_000141_000019_leftImg8bit.png\",\n","      \"monchengladbach_000000_007098_leftImg8bit.png\", \"cologne_000006_000019_leftImg8bit.png\", \"bremen_000256_000019_leftImg8bit.png\",\n","      \"bremen_000190_000019_leftImg8bit.png\", \"cologne_000072_000019_leftImg8bit.png\", \"cologne_000064_000019_leftImg8bit.png\", \"strasbourg_000000_029020_leftImg8bit.png\", # 10 primeros\n","      \"aachen_000137_000019_leftImg8bit.png\", \"dusseldorf_000030_000019_leftImg8bit.png\", \"bremen_000004_000019_leftImg8bit.png\", \"bremen_000085_000019_leftImg8bit.png\",\n","      \"dusseldorf_000026_000019_leftImg8bit.png\", \"bochum_000000_009951_leftImg8bit.png\", \"tubingen_000120_000019_leftImg8bit.png\", \"hamburg_000000_032906_leftImg8bit.png\",\n","      \"hanover_000000_055800_leftImg8bit.png\", \"monchengladbach_000000_033454_leftImg8bit.png\", \"stuttgart_000065_000019_leftImg8bit.png\", \"bremen_000183_000019_leftImg8bit.png\",\n","      \"bremen_000079_000019_leftImg8bit.png\", \"stuttgart_000087_000019_leftImg8bit.png\", \"tubingen_000035_000019_leftImg8bit.png\", \"strasbourg_000001_022151_leftImg8bit.png\",\n","      \"aachen_000140_000019_leftImg8bit.png\", \"cologne_000094_000019_leftImg8bit.png\", \"jena_000052_000019_leftImg8bit.png\", \"tubingen_000059_000019_leftImg8bit.png\",\n","      \"aachen_000009_000019_leftImg8bit.png\", \"darmstadt_000074_000019_leftImg8bit.png\", \"strasbourg_000000_013863_leftImg8bit.png\", \"aachen_000097_000019_leftImg8bit.png\",\n","      \"dusseldorf_000033_000019_leftImg8bit.png\", \"cologne_000145_000019_leftImg8bit.png\", \"krefeld_000000_021222_leftImg8bit.png\", \"hamburg_000000_078407_leftImg8bit.png\",\n","      \"hamburg_000000_053486_leftImg8bit.png\", \"hanover_000000_026804_leftImg8bit.png\", \"bremen_000121_000019_leftImg8bit.png\", \"stuttgart_000012_000019_leftImg8bit.png\",\n","      \"bremen_000135_000019_leftImg8bit.png\", \"jena_000070_000019_leftImg8bit.png\", \"bochum_000000_023040_leftImg8bit.png\", \"jena_000108_000019_leftImg8bit.png\",\n","      \"stuttgart_000155_000019_leftImg8bit.png\", \"bochum_000000_030913_leftImg8bit.png\", \"strasbourg_000001_031272_leftImg8bit.png\", \"tubingen_000075_000019_leftImg8bit.png\",\n","      \"tubingen_000048_000019_leftImg8bit.png\", \"cologne_000005_000019_leftImg8bit.png\", \"dusseldorf_000097_000019_leftImg8bit.png\", \"bremen_000059_000019_leftImg8bit.png\",\n","      \"hamburg_000000_098400_leftImg8bit.png\", \"hamburg_000000_081299_leftImg8bit.png\", \"aachen_000004_000019_leftImg8bit.png\", \"hamburg_000000_079376_leftImg8bit.png\",\n","      \"bremen_000112_000019_leftImg8bit.png\", \"monchengladbach_000000_006518_leftImg8bit.png\"]\n","\n","\n","for i in range(itera):\n","  images_GTA[i] = path_GTA + a[i]\n","  images_Reales[i] = path_Reales + b[i]"]},{"cell_type":"markdown","source":["## Para saber que imágenes que se han escogido"],"metadata":{"id":"kq9L0vIuovJ0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpH147INf0Vx"},"outputs":[],"source":["for name in images_GTA:\n","  print(name.split(\"/\")[-1])\n","print(\"------------------------------------------------\")\n","for name in images_Reales:\n","  print(name.split(\"/\")[-1])"]},{"cell_type":"markdown","source":["## Creamos la estructura de los datos"],"metadata":{"id":"rHClNtuAo2rH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8Kl4YDMbi5u"},"outputs":[],"source":["dataset_gta = tf.data.Dataset.from_generator(\n","    generator_gta,\n","    output_signature=(\n","        tf.TensorSpec((286, 286, 3), tf.int32)\n","    )\n",")\n","\n","dataset_cityscapes = tf.data.Dataset.from_generator(\n","    generator_cityscapes,\n","    output_signature=(\n","        tf.TensorSpec((286, 286, 3), tf.int32)\n","    )\n",")\n","\n","dataset_gta_rdy = dataset_gta.map(preprocess_imgs)\n","dataset_cityscapes_rdy = dataset_cityscapes.map(preprocess_imgs)\n","\n","dataset_full = tf.data.Dataset.zip((dataset_gta_rdy, dataset_cityscapes_rdy))"]},{"cell_type":"markdown","metadata":{"id":"OBZxzvSVk1c2"},"source":["# Automático para muchos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3D4-nh7bZTR"},"outputs":[],"source":["for num in range(0, itera):\n","\n","# GAN  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  i = 0\n","  for a, b in dataset_full.batch(1):\n","    if i==num:\n","      img_gta = a\n","      img_cs = b\n","    i += 1\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-6')\n","  Output_GAN_6 = generator_g.predict(img_gta)\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-10')\n","  Output_GAN_10 = generator_g.predict(img_gta)\n","\n","  ckpt.restore('/content/drive/MyDrive/CycleGTA/ckpt-12')\n","  Output_GAN_12 = generator_g.predict(img_gta)\n","\n","# Guardamos los resultados\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_6.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_6_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_10.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_10_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  fig, axes = plt.subplots(1,1)\n","  plt.imshow(renormalize(Output_GAN_12.squeeze())), plt.axis('off')\n","  plt.savefig(path_result + \"Output_GAN_12_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","\n","# Segmentación  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","  images_name = [\"GTA/\" + images_GTA[num].split(\"/\")[-1], \"Resultados/Output_GAN_6_\" + str(num+1) + \".png\",\n","                 \"Resultados/Output_GAN_10_\" + str(num+1) + \".png\", \"Resultados/Output_GAN_12_\" + str(num+1) + \".png\"]\n","\n","  mask_names = ((images_name[0].split(\"/\")[-1] + \" \") * 4).split()\n","\n","  dataset = tf.data.Dataset.from_tensor_slices((images_name, mask_names))\n","  dataset = dataset.map(load_train, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n","  dataset = dataset.batch(batch_size)\n","\n","  predictions = model.predict(dataset, batch_size = 10)\n","  predictions = np.argmax(predictions, axis = 3)\n","\n","  idx = range(len(images_name))\n","  visualize_images = [load_image(train_images_folder_path, images_name[i], img_height, img_width) for i in idx]\n","  visualize_masks = [load_mask(train_mask_folder_path, mask_names[i], img_height, img_width, one_hot = False) for i in idx]\n","  preds = predictions[idx]\n","\n","  iou_score = []\n","  iou_score_half = []\n","\n","  plt.figure(figsize = (16, 4))\n","  plt.subplots_adjust(hspace = 0.1)\n","\n","  for k in range(4):\n","    plt.subplot(3, 4, k + 1)\n","    plt.imshow(visualize_images[k])\n","    # if k==0:\n","    #   plt.ylabel(\"Input\")\n","    # plt.title(rango[k])\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","    plt.subplot(3, 4, k + 5)\n","    plt.imshow(visualize_masks[k])\n","    # if k==0:\n","    #   plt.ylabel(\"Ground Truth\")\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","    output = one_hot_to_color_mask(preds[k], colors)\n","# IoU calculation\n","    intersection = 0\n","    union = img_height * img_width\n","\n","    for i in range(img_height):\n","      for j in range(img_width):\n","        a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","        if sum(a.numpy())==3:\n","          intersection += 1\n","\n","    iou_score.append(round(intersection/union, ndigits=2))\n","    \n","# Calcula de la mitad hacia abajo\n","    intersection = 0\n","    union = int(img_height/2) * img_width\n","\n","    for i in range(int(img_height/2), img_height):\n","        for j in range(img_width):\n","          a = visualize_masks[k][i-1,j-1,:] == output[i-1,j-1,:]\n","          if sum(a.numpy())==3:\n","            intersection += 1\n","\n","    iou_score_half.append(round(intersection/union, ndigits=2))\n","    \n","    plt.subplot(3, 4, k + 9)\n","    plt.imshow(output)\n","    # if k==0:\n","    #   plt.ylabel(\"Output\")\n","    plt.xlabel(\"IoU: %s\" % iou_score[k])\n","    plt.yticks(())\n","    plt.xticks(())\n","\n","  plt.savefig(path_result + \"Output_GTA_\" + str(num+1) + \".png\", bbox_inches=\"tight\", pad_inches=0)\n","\n","  print(\"Completado el\", str(num+1))"]}],"metadata":{"colab":{"collapsed_sections":["L6ejeVWQlC2r","Nx3vpg7TfFTT","eV5ITTLefOeX","EwIv0X3rfRFn","Q8fKCOyBfbEL","kq9L0vIuovJ0","rHClNtuAo2rH"],"provenance":[],"authorship_tag":"ABX9TyOW3pasA8oslwc+bJgrmHBf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}